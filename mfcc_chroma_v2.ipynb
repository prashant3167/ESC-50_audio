{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_features(file_name, type=\"mfcc\"):\n",
    "    # Load audio file\n",
    "    file_path = \"/Users/Licious/project/unipd/hda_dataset/audio/\"+ file_name\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Extract MFCCs (Mel-Frequency Cepstral Coefficients)\n",
    "    if type==\"mfcc\":\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        return mfccs\n",
    "    elif type==\"chroma\":\n",
    "    # print(mfccs)\n",
    "    # Extract Chroma feature\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        return chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_test_spit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Feature extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Licious/project/DataPlatform/pydev/lib/python3.9/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Feature extraction\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load and preprocess the dataset\n",
    "def load_and_preprocess_data():\n",
    "    # Assume you have a list of file paths and corresponding labels\n",
    "    meta = pd.read_csv(\"/Users/Licious/project/unipd/hda_dataset/meta/esc50.csv\")\n",
    "\n",
    "    file_paths = meta[\"filename\"].to_list()\n",
    "    labels = meta[\"target\"].to_list()\n",
    "\n",
    "    # Extract features for each audio file\n",
    "    feature_mfcc = [extract_features(file_path, type=\"mfcc\") for file_path in file_paths]\n",
    "    features_chroma = [extract_features(file_path, type=\"chroma\") for file_path in file_paths]\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    feature_mfcc = np.array(feature_mfcc)\n",
    "    features_chroma = np.array(features_chroma)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return feature_mfcc,features_chroma, labels\n",
    "\n",
    "num_classes = 50\n",
    "# Load and preprocess the data\n",
    "# dataset_path = \"path/to/your/dataset\"\n",
    "print(\"Start Feature extraction\")\n",
    "feature_mfcc, features_chroma, labels = load_and_preprocess_data()\n",
    "print(\"End Feature extraction\")\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_mfcc, X_test_mfcc, X_train_chroma, X_test_chroma, y_train, y_test = train_test_split(feature_mfcc, features_chroma, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Licious/project/DataPlatform/pydev/lib/python3.9/site-packages/keras/src/engine/functional.py:639: UserWarning: Input dict contained keys ['chroma_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 9s 291ms/step - loss: 6.1016 - accuracy: 0.0981 - val_loss: 7.0395 - val_accuracy: 0.0275\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 6s 259ms/step - loss: 4.8103 - accuracy: 0.2050 - val_loss: 6.3074 - val_accuracy: 0.0475\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 6s 255ms/step - loss: 4.0556 - accuracy: 0.2713 - val_loss: 5.8585 - val_accuracy: 0.0750\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 6s 260ms/step - loss: 3.6017 - accuracy: 0.3094 - val_loss: 4.6532 - val_accuracy: 0.1400\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 6s 256ms/step - loss: 3.2586 - accuracy: 0.3431 - val_loss: 4.3762 - val_accuracy: 0.1800\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 6s 259ms/step - loss: 2.9232 - accuracy: 0.4087 - val_loss: 3.5980 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 7s 266ms/step - loss: 2.7513 - accuracy: 0.4156 - val_loss: 3.4075 - val_accuracy: 0.3025\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 6s 258ms/step - loss: 2.5299 - accuracy: 0.4700 - val_loss: 3.3937 - val_accuracy: 0.3075\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 6s 260ms/step - loss: 2.4226 - accuracy: 0.4812 - val_loss: 2.9504 - val_accuracy: 0.3750\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 6s 256ms/step - loss: 2.2740 - accuracy: 0.5119 - val_loss: 2.8413 - val_accuracy: 0.4150\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 2.8413 - accuracy: 0.4150\n",
      "Test Accuracy: 0.41499999165534973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have feature_mfcc, features_chroma, and labels as your original datasets\n",
    "\n",
    "# Use train_test_split to split the data into training and testing sets\n",
    "# X_train_mfcc, X_test_mfcc, X_train_chroma, X_test_chroma, y_train, y_test = train_test_split(\n",
    "#     feature_mfcc, features_chroma, labels, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# Build the model\n",
    "mfcc_input = layers.Input(shape=(X_train_mfcc.shape[1], X_train_mfcc.shape[2],1), name='mfcc_input')\n",
    "mfcc_conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='valid')(mfcc_input)\n",
    "mfcc_pool1 = layers.MaxPooling2D(pool_size=(2, 2))(mfcc_conv1)\n",
    "mfcc_batch_norm1 = layers.BatchNormalization()(mfcc_pool1)\n",
    "mfcc_conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid')(mfcc_batch_norm1)\n",
    "mfcc_pool2 = layers.MaxPooling2D(pool_size=(2, 2))(mfcc_conv2)\n",
    "mfcc_batch_norm2 = layers.BatchNormalization()(mfcc_pool2)\n",
    "\n",
    "# chroma_input = layers.Input(shape=(X_train_chroma.shape[1], X_train_chroma.shape[2],1), name='chroma_input')\n",
    "# chroma_conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='valid')(chroma_input)\n",
    "# chroma_pool1 = layers.MaxPooling2D(pool_size=(2, 2))(chroma_conv1)\n",
    "# chroma_batch_norm1 = layers.BatchNormalization()(chroma_pool1)\n",
    "# chroma_conv2 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid')(chroma_batch_norm1)\n",
    "# chroma_pool2 = layers.MaxPooling2D(pool_size=(2, 2))(chroma_conv2)\n",
    "# chroma_batch_norm2 = layers.BatchNormalization()(chroma_pool2)\n",
    "\n",
    "# merged = layers.Concatenate()([mfcc_batch_norm2, chroma_batch_norm2])\n",
    "merged = layers.Concatenate()([mfcc_batch_norm2])\n",
    "\n",
    "reshaped = layers.Reshape((106, 64))(merged)\n",
    "lstm1 = layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2')(reshaped)\n",
    "lstm2 = layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2')(lstm1)\n",
    "lstm3 = layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2')(lstm2)\n",
    "\n",
    "flat = layers.Flatten()(lstm3)\n",
    "dense1 = layers.Dense(128, activation='relu')(flat)\n",
    "dropout = layers.Dropout(0.5)(dense1)\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(dropout)\n",
    "\n",
    "model = models.Model(inputs=[mfcc_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit({'mfcc_input': X_train_mfcc, 'chroma_input': X_train_chroma}, y_train, epochs=10, batch_size=64,\n",
    "          validation_data=({'mfcc_input': X_test_mfcc, 'chroma_input': X_test_chroma}, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate({'mfcc_input': X_test_mfcc, 'chroma_input': X_test_chroma}, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_mfcc.reshape(X_train_mfcc.shape[0], X_train_mfcc.shape[1], X_train_mfcc.shape[2], 1)\n",
    "X_test = X_test_mfcc.reshape(X_test_mfcc.shape[0], X_test_mfcc.shape[1], X_test_mfcc.shape[2], 1)\n",
    "\n",
    "# CRNN Model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers for feature extraction\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1), padding='valid'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Reshape for recurrent layers\n",
    "\n",
    "model.add(layers.Reshape((106, 64)))\n",
    "# model.add(layers.LSTM(64, return_sequences=True))\n",
    "# Example: Add dropout to LSTM layers\n",
    "model.add(layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2'))\n",
    "# Example: Add dropout to LSTM layers\n",
    "model.add(layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2'))\n",
    "# Example: Add dropout to LSTM layers\n",
    "model.add(layers.LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2'))\n",
    "\n",
    "# model.add(layers.LSTM(64, return_sequences=True))\n",
    "# model.add(layers.LSTM(64, return_sequences=True))\n",
    "\n",
    "# Flatten and Dense layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "num_classes = len(np.unique(labels))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
